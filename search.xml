<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring 解决循环依赖必须要三级缓存吗？]]></title>
    <url>%2F2021%2F09%2F23%2Fspring-level-3-cache%2F</url>
    <content type="text"><![CDATA[转载自:https://juejin.cn/post/6882266649509298189 我们都知道 Spring 是通过三级缓存来解决循环依赖的，但是解决循环依赖真的需要使用到三级缓冲吗？只使用两级缓存是否可以呢？本篇文章就 Spring 是如何使用三级缓存解决循环依赖作为引子，验证两级缓存是否可以解决循环依赖。 循环依赖既然要解决循环依赖，那么就要知道循环依赖是什么。如下图所示：通过上图，我们可以看出：A 依赖于 BB 依赖于 CC 依赖于 A1234567891011public class A &#123; private B b;&#125;public class B &#123; private C c;&#125;public class C &#123; private A a;&#125; 这种依赖关系形成了一种闭环，从而造成了循环依赖的局面。下面是未解决循环依赖的常规步骤： 1、实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行。2、A 对象发现需要注入 B 对象，但是容器中并没有 B 对象（如果对象创建完成并且属性注入完成和执行完初始化方法就会放入容器中）。3、实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行。4、B 对象发现需要注入 C 对象，但是容器中并没有 C 对象。5、实例化 C，此时 C 还未完成属性填充和初始化方法（@PostConstruct）的执行。6、C 对象发现需要注入 A 对象，但是容器中并没有 A 对象。7、重复步骤 1。 三级缓存Spring 解决循环依赖的核心就是提前暴露对象，而提前暴露的对象就是放置于第二级缓存中。下表是三级缓存的说明： singletonObjects：一级缓存，存放完整的 Bean。 earlySingletonObjects ：二级缓存，存放提前暴露的Bean，Bean 是不完整的，未完成属性注入和执行 init 方法。 singletonFactories：三级缓存，存放的是 Bean 工厂，主要是生产 Bean，存放到二级缓存中。 所有被 Spring 管理的 Bean，最终都会存放在 singletonObjects 中，这里面存放的 Bean 是经历了所有生命周期的（除了销毁的生命周期），完整的，可以给用户使用的。earlySingletonObjects 存放的是已经被实例化，但是还没有注入属性和执行 init 方法的 Bean。singletonFactories 存放的是生产 Bean 的工厂。Bean 都已经实例化了，为什么还需要一个生产 Bean 的工厂呢？这里实际上是跟 AOP 有关，如果项目中不需要为 Bean 进行代理，那么这个 Bean 工厂就会直接返回一开始实例化的对象，如果需要使用 AOP 进行代理，那么这个工厂就会发挥重要的作用了，这也是本文需要重点关注的问题之一。 解决循环依赖Spring 是如何通过上面介绍的三级缓存来解决循环依赖的呢？这里只用 A，B 形成的循环依赖来举例： 1、实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行，A 只是一个半成品。2、为 A 创建一个 Bean 工厂，并放入到 singletonFactories 中。3、发现 A 需要注入 B 对象，但是一级、二级、三级缓存均为发现对象 B。4、实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行，B 只是一个半成品。5、为 B 创建一个 Bean 工厂，并放入到 singletonFactories 中。6、发现 B 需要注入 A 对象，此时在一级、二级未发现对象 A，但是在三级缓存中发现了对象 A，从三级缓存中得到对象 A，并将对象 A 放入二级缓存中，同时删除三级缓存中的对象 A。（注意，此时的 A 还是一个半成品，并没有完成属性填充和执行初始化方法）7、将对象 A 注入到对象 B 中。8、对象 B 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 B。（此时对象 B 已经是一个成品）9、对象 A 得到对象 B，将对象 B 注入到对象 A 中。（对象 A 得到的是一个完整的对象 B）10、对象 A 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 A。 我们从源码中来分析整个过程：创建 Bean 的方法在 AbstractAutowireCapableBeanFactory::doCreateBean()1234567891011121314151617181920212223242526protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; BeanWrapper instanceWrapper = null; if (instanceWrapper == null) &#123; // ① 实例化对象 instanceWrapper = this.createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null; Class&lt;?&gt; beanType = instanceWrapper != null ? instanceWrapper.getWrappedClass() : null; // ② 判断是否允许提前暴露对象，如果允许，则直接添加一个 ObjectFactory 到三级缓存 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; // 添加三级缓存的方法详情在下方 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // ③ 填充属性 this.populateBean(beanName, mbd, instanceWrapper); // ④ 执行初始化方法，并创建代理 exposedObject = initializeBean(beanName, exposedObject, mbd); return exposedObject;&#125; 添加三级缓存的方法如下：123456789101112131415protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; // 判断一级缓存中不存在此对象 this.singletonFactories.put(beanName, singletonFactory); // 添加至三级缓存 this.earlySingletonObjects.remove(beanName); // 确保二级缓存没有此对象 this.registeredSingletons.add(beanName); &#125; &#125;&#125;@FunctionalInterfacepublic interface ObjectFactory&lt;T&gt; &#123; T getObject() throws BeansException;&#125; 通过这段代码，我们可以知道 Spring 在实例化对象的之后，就会为其创建一个 Bean 工厂，并将此工厂加入到三级缓存中。 因此，Spring 一开始提前暴露的并不是实例化的 Bean，而是将 Bean 包装起来的 ObjectFactory。为什么要这么做呢？ 这实际上涉及到 AOP，如果创建的 Bean 是有代理的，那么注入的就应该是代理 Bean，而不是原始的 Bean。但是 Spring 一开始并不知道 Bean 是否会有循环依赖，通常情况下（没有循环依赖的情况下），Spring 都会在完成填充属性，并且执行完初始化方法之后再为其创建代理。但是，如果出现了循环依赖的话，Spring 就不得不为其提前创建代理对象，否则注入的就是一个原始对象，而不是代理对象。因此，这里就涉及到应该在哪里提前创建代理对象？Spring 的做法就是在 ObjectFactory 中去提前创建代理对象。它会执行 getObject() 方法来获取到 Bean。实际上，它真正执行的方法如下：12345678910111213protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; // 如果需要代理，这里会返回代理对象；否则返回原始对象 exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject;&#125; 因为提前进行了代理，避免对后面重复创建代理对象，会在 earlyProxyReferences 中记录已被代理的对象。12345678910public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; @Override public Object getEarlyBeanReference(Object bean, String beanName) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); // 记录已被代理的对象 this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125;&#125; 通过上面的解析，我们可以知道 Spring 需要三级缓存的目的是为了在没有循环依赖的情况下，延迟代理对象的创建，使 Bean 的创建符合 Spring 的设计原则。 如何获取依赖我们目前已经知道了 Spring 的三级依赖的作用，但是 Spring 在注入属性的时候是如何去获取依赖的呢？ 他是通过一个 getSingleton() 方法去获取所需要的 Bean 的。12345678910111213141516171819202122protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 一级缓存 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 二级缓存 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 三级缓存 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; // Bean 工厂中获取 Bean singletonObject = singletonFactory.getObject(); // 放入到二级缓存中 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125; 当 Spring 为某个 Bean 填充属性的时候，它首先会寻找需要注入对象的名称，然后依次执行 getSingleton() 方法得到所需注入的对象，而获取对象的过程就是先从一级缓存中获取，一级缓存中没有就从二级缓存中获取，二级缓存中没有就从三级缓存中获取，如果三级缓存中也没有，那么就会去执行 doCreateBean() 方法创建这个 Bean。 二级缓存我们现在已经知道，第三级缓存的目的是为了延迟代理对象的创建，因为如果没有依赖循环的话，那么就不需要为其提前创建代理，可以将它延迟到初始化完成之后再创建。既然目的只是延迟的话，那么我们是不是可以不延迟创建，而是在实例化完成之后，就为其创建代理对象，这样我们就不需要第三级缓存了。因此，我们可以将addSingletonFactory()方法进行改造。12345678910protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; // 判断一级缓存中不存在此对象 object o = singletonFactory.getObject(); // 直接从工厂中获取 Bean this.earlySingletonObjects.put(beanName, o); // 添加至二级缓存中 this.registeredSingletons.add(beanName); &#125; &#125;&#125; 这样的话，每次实例化完 Bean 之后就直接去创建代理对象，并添加到二级缓存中。测试结果是完全正常的，Spring 的初始化时间应该也是不会有太大的影响，因为如果 Bean 本身不需要代理的话，是直接返回原始 Bean 的，并不需要走复杂的创建代理 Bean 的流程。 结论测试证明，二级缓存也是可以解决循环依赖的。为什么 Spring 不选择二级缓存，而要额外多添加一层缓存呢？如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。 下面是一些自己的总结： 通过debug源码发现，第三级缓存里面存放的是singletonFactory，所以如果只有两级缓存的话，二级缓存放的就应该是调用singletonFactory.getObject()拿到的bean。到这里，假如不存在AOP的话是完全没有问题的，如果存在AOP，那么二级缓存里面放的就必须是代理后的bean，因为Spring事先并不知道是否存在循环依赖，所以只能都放代理后的bean（循环依赖的情况下必须提前创建代理对象），这个时候问题就来了，如果不存在循环依赖，又提前创建了代理对象，就不符合Spring延迟创建代理对象的设计原则了，这个问题二级缓存是没办法解决的，必须依赖三级缓存。通过源码也可以看到getEarlyBeanReference这个方法，只有在存在循环依赖的情况下，这个方法才会被调用，而提前创建代理对象正是在这里创建的，所以三级缓存完美的解决了这个问题。以上是自己看完以后的一些总结，如果有误，欢迎大家指正！]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exception和Error有什么区别？]]></title>
    <url>%2F2020%2F03%2F14%2Fexception-and-error%2F</url>
    <content type="text"><![CDATA[Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw）或者捕获（catch），它是异常处理机制的基本组成类型。 Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。 Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。 Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。前面我介绍的不可查的 Error，是 Throwable 不是 Exception。 不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。 实践中的一些经验： 尽量不要捕获类似 Exception 这样的通用异常，而是应该捕获特定异常，这是因为在日常的开发和合作中，我们读代码的机会往往超过写代码，软件工程是门协作的艺术，所以我们有义务让自己的代码能够直观地体现出尽量多的信息，而泛泛的 Exception 之类，恰恰隐藏了我们的目的。另外，我们也要保证程序不会捕获到我们不希望捕获的异常。比如，你可能更希望 RuntimeException 被扩散出来，而不是被捕获。进一步讲，除非深思熟虑了，否则不要捕获 Throwable 或者 Error，这样很难保证我们能够正确程序处理 OutOfMemoryError。 不要生吞（swallow）异常。这是异常处理中要特别注意的事情，因为很可能会导致非常难以诊断的诡异情况。生吞异常，往往是基于假设这段代码可能不会发生，或者感觉忽略异常是无所谓的，但是千万不要在产品代码做这种假设！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何用较少的代码实现一个死锁？]]></title>
    <url>%2F2020%2F02%2F28%2FdeadLock%2F</url>
    <content type="text"><![CDATA[前言死锁是面试中经常会被问到的一个问题，对于什么是死锁，大家肯定早已经烂熟于心了，但是如果面试官让你现场写一段死锁的代码，估计很多人就有点慌了。毕竟记住了概念是一回事，能自己写出来又是另一回事。前几天在看一个JVM视频的时候，发现一个例子写的很好，理解起来也很简单，给大家分享一下： 这个逻辑很简单，新建了两个类A和B，有两个相同的方法method()，逻辑也很简单，就输出一句话，然后调用另一个类的method()方法，为了达到理想的效果，让持有该锁的线程休眠了5秒。main函数里面，启动了两个线程去分别调用类A的method方法和类B的method方法，这里用到了Lambda表达式。当第一个线程进入类A的method方法后，休眠了5秒之后，准备去调用类B的method方法，此时，类B的Class对象的锁被另一个线程锁持有，只能等待。与此同时，第二个线程也执行了相同的操作，想要去获取类A的Class对象的锁，然后发现锁已被第一个线程持有，也进入了等待的状态。这样，两个线程就在互相等待对方释放锁，而进入了永久循环的状态。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈一谈Java的“一次编译、到处运行”]]></title>
    <url>%2F2019%2F07%2F23%2Fwrite-once-run-anywhere%2F</url>
    <content type="text"><![CDATA[“一次编译、到处运行”说的是Java语言跨平台的特性，Java的跨平台特性与Java虚拟机的存在密不可分，可在不同的环境中运行。比如说Windows平台和Linux平台都有相应的JDK，安装好JDK后也就有了Java语言的运行环境。其实Java语言本身与其他的编程语言没有特别大的差异，并不是说Java语言可以跨平台，而是在不同的平台都有可以让Java语言运行的环境而已，所以才有了Java一次编译，到处运行这样的效果。 严格的讲，跨平台的语言不止Java一种，但Java是较为成熟的一种。“一次编译，到处运行”这种效果跟编译器有关。编程语言的处理需要编译器和解释器。Java虚拟机和DOS类似，相当于一个供程序运行的平台。 程序从源代码到运行的三个阶段：编码——编译——运行——调试。Java在编译阶段则体现了跨平台的特点。编译过程大概是这样的：首先是将Java源代码转化成.CLASS文件字节码，这是第一次编译。.class文件就是可以到处运行的文件。然后Java字节码会被转化为目标机器代码，这是是由JVM来执行的，即Java的第二次编译。 “到处运行”的关键和前提就是JVM。因为在第二次编译中JVM起着关键作用。在可以运行Java虚拟机的地方都内含着一个JVM操作系统。从而使JAVA提供了各种不同平台上的虚拟机制，因此实现了“到处运行”的效果。需要强调的一点是，java并不是编译机制，而是解释机制。Java字节码的设计充分考虑了JIT这一即时编译方式，可以将字节码直接转化成高性能的本地机器码，这同样是虚拟机的一个构成部分。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-generator生成代码时报错：Could not create connection to database server.]]></title>
    <url>%2F2019%2F04%2F23%2Fmybatis-generator-report-error%2F</url>
    <content type="text"><![CDATA[前言今天在写一个小项目的时候，需要用到mybatis-generator来帮我自动生成一些代码，数据库安装的是当时最新的MySQL 8.0.15版本,generatorConfig.xml配置如下:运行mybatis-generator的maven plugin的时候，一直报错：Could not create connection to database server. 后来通过排查，发现原因是，MySQL8.0之后的版本需要更换驱动为“com.mysql.cj.jdbc.Driver”，之前的“com.mysql.jdbc.Driver”已经不能在MySQL 8.0之后的版本使用了，官方文档链接：https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-api-changes.html 原文如下：The name of the class that implements java.sql.Driver in MySQL Connector/J has changed from com.mysql.jdbc.Driver to com.mysql.cj.jdbc.Driver. The old class name has been deprecated.所以，修改以下两个地方就Ok了： 1.更新pom文件中mysql-connector-java的版本 2.更新mybatis-generator配置文件generatorConfig.xml中的驱动： 更新之后，再次运行mybatis-generator-maven-plugin，成功生成了dao层接口和mapper文件：]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化的方式]]></title>
    <url>%2F2019%2F04%2F10%2Fredis-data-persistence%2F</url>
    <content type="text"><![CDATA[最近面试的时候，几乎每家公司都问到了Redis的持久化问题，回来以后翻了一下资料，发现自己回答的不是很完整，所以来总结一下，加深理解。Redis持久化的方式有两种： 1.RDBRDB（Redis Database）,在指定的时间间隔能对数据进行快照存储,是Redis默认的持久化方式，这种方式是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。我们可以配置redis在n秒内如果超过m个key被修改就自动做快照，下面是默认的快照保存配置:123save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒内容如超过10个key被修改，则发起快照保存save 60 10000 RDB文件的保存过程 redis调用fork,现在有了子进程和父进程。 父进程继续处理client请求，子进程负责将内存内容写入到临时文件。由于os的写时复制机制（copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时os会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程的地址空间内的数 据是fork时刻整个数据库的一个快照。 当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出。 client 也可以使用save或者bgsave命令通知redis做一次快照持久化。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有 client的请求，这种方式会阻塞所有client请求。所以不推荐使用。另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不 是增量的只同步脏数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io操作，可能会严重影响性能。 RDB的优点 使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能。 数据量比较大的时候，RDB比AOF速度更快。 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这样非常方便进行备份。比如你可能打算每隔一天归档一些数据。RDB的缺点 RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失，数据的准确性不高。虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。在这种情况下，一旦发生故障停机，你就可能会丢失好几分钟的数据，不要觉得这几分钟很短，造成的损失可能是你想不到的，所以如果你对数据的准确性要求比较高，那么你应该选择AOF。 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 2.AOFAOF(Append Only File)，AOF持久化方式记录每次对服务器写的操作,通过write函数追加到文件中(默认是 appendonly.aof)，当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。我们可以通过配置文件告诉redis我们想要 通过fsync函数强制os写入到磁盘的时机。有三种方式如下（默认是：每秒fsync一次）1234appendonly yes //启用aof持久化方式appendfsync always //每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用appendfsync everysec //每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐appendfsync no //完全依赖os，性能最好,持久化没保证 aof 的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用incr test命令100次，文件中必须保存全部的100条命令，其实有99条都是多余的。因为要恢复数据库的状态其实文件中保存一条set test 100就够了。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。收到此命令redis将使用与快照类似的方式将内存中的数据 以命令的方式保存到临时文件中，最后替换原来的文件。 AOF文件保存过程 redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 需要注意到是重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件,这点和快照有点类似。 AOF的优点可以保持更高的数据完整性，因此已成为主流的持久化方案. AOF的缺点AOF文件比RDB文件大，且恢复速度慢。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装MySQL]]></title>
    <url>%2F2019%2F04%2F09%2Fdocker-install-mysql%2F</url>
    <content type="text"><![CDATA[1. 前言mysql都已经更新到8了，听说速度比5.X快了不少，正好最近要做一个小项目，就赶紧装个最新的版本来爽一下。 2. 安装2.1 docker 中下载 mysql1docker pull mysql #如果不指定版本，默认是latest 2.2 启动1docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=admin -d mysql #密码不要抄我的！！！ 2.3 进入容器docker exec -it mysql bash 2.4 登录mysqlmysql -u root -p ALTER USER 'root'@'localhost' IDENTIFIED BY 'admin'; 2.5 添加远程登录用户CREATE USER 'zhouyn'@'%' IDENTIFIED WITH mysql_native_password BY 'admin'; GRANT ALL PRIVILEGES ON *.* TO 'zhouyn'@'%'; 3. 安装过程中出现的问题暂时没出现啥问题，一次安装成功，惊不惊喜？意不意外？先待定，后面出现啥问题再补充。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2019%2F04%2F08%2Fdocker%2F</url>
    <content type="text"><![CDATA[1.前言Docker火了已经有一段时间了，但是因为所在公司的原因，一直没有机会接触到这些新技术，公司主要的业务是电信行业，技术栈也是自己搞的一套，先不说好不好吧，反正我觉得是什么都学不到，当然，也有我自己的问题，虽然公司用的技术比较老，但是只要自己愿意学的话，还是可以学到东西的，但是对着一堆陈年老代码，我实在是没有什么欲望，所以，年后就果断离职了。出来面试了一圈才知道，大家现在都在整springBoot+springCloud这一套了，面试完也拿了几个offer，但自己心仪的几个公司都被拒了，每次面试完都会回去反思一下，入职某信的这半年多时间，在技术上几乎没有任何的沉淀，学到的一些新东西，也是公司自己内部的，外面的公司根本不知道，所以还是庆幸自己早点跳出来了，不然可能时间越长就越没法跳出来了，从我那些同事那就能看的出来，所以也劝大家选行业的时候一定要慎重，对你以后的发展很重要，电信行业已经进入我的黑名单，以后再也不想入这一行了。 2.关于Docker刚才有感而发说了些废话，现在开始说正事吧。关于什么是Docker以及和虚拟机的区别，网上一搜一大堆，我就不再当搬运工了，只要是做这一行的，一看就能明白他俩的区别，Docker能火起来是个必然的趋势，这一点我深有感触，以前配一套环境，要折腾很久，现在分分钟搞定，简直爽歪歪！ 3.Docker的安装我用的是macOS和Linux的系统，安装过程很简单，网上的教程也很多，各种OS的都有，大家照着安装就可以了，本文只是做个铺垫，后面会记录一下其他和Docker相关的东西。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈一谈对Java的理解]]></title>
    <url>%2F2019%2F04%2F06%2Ftalk-about-the-undertandng-of-Java%2F</url>
    <content type="text"><![CDATA[从接触 Java 开发到现在，你觉得你对 Java 最直观的印象是什么？是它宣传的 “Write once, run anywhere”，还是目前看已经有些过于形式主义的语法？ 特性Java 本身是一种面向对象的语言，最显著的特性有两个方面，一是所谓的“一次编译，到处运行”（Write once, run anywhere），能够非常容易地获得跨平台能力；另外就是垃圾收集（GC, Garbage Collection），Java 通过垃圾收集器（Garbage Collector）回收分配内存，大部分情况下，程序员不需要自己操心内存的分配和回收。 JRE&amp;JDK我们日常会接触到 JRE（Java Runtime Environment）或者 JDK（Java Development Kit）。 JRE，也就是 Java 运行环境，包含了 JVM 和 Java 类库，以及一些模块等。而 JDK 可以看作是 JRE 的一个超集，提供了更多工具，比如编译器、各种诊断工具等。 Java 是解释执行？对于“Java 是解释执行”这句话，这个说法不太准确。我们开发的 Java 的源代码，首先通过 Javac 编译成为字节码（bytecode），然后，在运行时，通过 Java 虚拟机（JVM）内嵌的解释器将字节码转换成为最终的机器码。但是常见的 JVM，比如我们大多数情况使用的 Oracle JDK 提供的 Hotspot JVM，都提供了 JIT（Just-In-Time）编译器，也就是通常所说的动态编译器，JIT 能够在运行时将热点代码编译成机器码，这种情况下部分热点代码就属于 一次编译、到处运行“一次编译、到处运行”说的是 Java 语言跨平台的特性，Java 的跨平台特性与 Java 虚拟机的存在密不可分，可在不同的环境中运行。比如说 Windows 平台和 Linux 平台都有相应的 JDK ，安装好 JDK后也就有了 Java 语言的运行环境。其实 Java 语言本身与其他的编程语言没有特别大的差异，并不是说 Java 语言可以跨平台，而是在不同的平台都有可以让 Java 语言运行的环境而已，所以才有了 Java 一次编译，到处运行这样的效果。严格的讲，跨平台的语言不止 Java 一种，但 Java 是较为成熟的一种。“一次编译，到处运行”这种效果跟编译器有关。编程语言的处理需要编译器和解释器。Java 虚拟机和 DOS 类似，相当于一个供程序运行的平台。程序从源代码到运行的三个阶段：编码——编译——运行——调试。Java 在编译阶段则体现了跨平台的特点。编译过程大概是这样的：首先是将 Java 源代码转化成 .CLASS 文件字节码，这是第一次编译。.class 文件就是可以到处运行的文件。然后Java字节码会被转化为目标机器代码，这是是由 JVM 来执行的，即 Java 的第二次编译。 JVM“到处运行”的关键和前提就是 JVM 。因为在第二次编译中 JVM 起着关键作用。在可以运行 Java 虚拟机的地方都内含着一个JVM操作系统。从而使 JAVA 提供了各种不同平台上的虚拟机制，因此实现了“到处运行”的效果。需要强调的一点是，java 并不是编译机制，而是解释机制。Java 字节码的设计充分考虑了 JIT 这一即时编译方式，可以将字节码直接转化成高性能的本地机器码，这同样是虚拟机的一个构成部分。 总结下面是一位大牛总结的蓝图，很全面，可以参考一下：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F31%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
